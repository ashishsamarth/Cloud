-----------------------------------------------------------------------------------------------------------------------------------------------------------
IAM: Identity & Access Management
-----------------------------------------------------------------------------------------------------------------------------------------------------------
1.  IAM is a global service in AWS. This can be verified by going to IAM Dashboard and when you try to select a region, you will see the following text
    'IAM does not require a region selection'
    It also indicates that all the users that are created in a particular AWS account are available in all regions.

    a.  The root user is the most powerful user (it can do anything and everything in an AWS account), hence its recommended to create new users to 
        perform specific tasks and limit their capabilites using policies and groups. Since we must follow the principle of least privilege.


    Q01: When creating a USER, how many types of 'Access Types' can be provisioned?
    A01: Their are two types of 'Access Types' that can be utilized

        a.  Programmatic Access: 
            This allows the user to use AWS API, CLI, SDK & Other development tools to be utilized via an access Key ID & secret access key
        b.  AWS Management Console Access: 
            This allows the user to use the (GUI) management console access.
    
    Q02. When creating a USER, is it necessary to Create a Group?
    A02: No, Its not necesary to create a Group while creating a USER. However, as a best practice its recommended to have even a single user to be 
        mapped to group.Since over a period of time, the number of users may grow and it will be easier to manage permissions using groups and policies.
    
    Q03: What are tags in AWS?
    A03: Tags are way to organize and categorize resources in AWS.
        Foe e.g.: Their are mulitple EC2 instances in your account, and you want to identify them based on Team names and/or Project Names to quickly 
        identify which EC2 instance is being used for what. Tagging also helps to identify the cost accumulated by the resources which is important for 
        Billing & Thresholds.
    
    Q04: Once the user is created, how many ways can the user get login credentials?
    A04: Their are two ways a user can get hold of login credentials
        a.  via the 'Download.csv'
        b.  'Send Email' : Which has the Email Login Instructions.

    Q05: How can you customize the url for specific user login, Once the user is created?
    A05: Login to the AWS console --> Go to IAM Dashboard --> on the top right under 'AWS Account' --> Look for 'Account Alias'
        a.  If you dont have an alias - It will enable the link to 'Create' an alias
        b.  If you have an alias - It will allow to 'Edit' or 'Delete' an alias

        Important Note: Since IAM is a Global Service, the alia that you create must be unique for entire IAM service across all regions.
        You cannot create an alias if it already exists.

        e.g.:   https://samarth-aws.signin.aws.amazon.com/console
    
    Q06: What is the advantage of having an alias based url for login?
    A06: Following are the advantages
        a.  When you use an 'Alias' based url:
            1.  Your 'Account ID or Alias' is already populated for you
            2.  You can directly login as an IAM user, rather than selecting the radio button between 'root user' vs 'iam user'
    
    Q07: How can you identify if a user is an IAM User vs a ROOT user, just by looking at the management console?
    A07: Once logged in, if you look at the top right of the screen where it shows the user
        a.  An IAM user will have the '@' keyword in the name:
            e.g.    samarth-developer@samarth-aws OR samarth-developer@account-id
        b.  A root user will not have the '@' keyword in the name
    
    Q08: Explain IAM Password Policy?
    A08: In AWS: You can set up a password policy to have
            a.  set a minimum password length
            b.  Require specific character types
                1.  including uppercase letters
                2.  including lowercase letters
                3.  including numbers
                4.  including non-alphanumeric characters
            c.  Allow all IAM users to change their own passwords
            d.  Require users to change their passwords after some time (password expiration)
            e.  Prevent password re-use
    
    Q09: What is the advantage of using an MFA?
    A09: AWS recommends to protect the root and iam users by using MFA (multi-factor-authentication)
        The main benefit of using an MFA is - Even if a password is stolen or hacked, the account will not be compromised.
        Following are the supported devices for MFA in AWS:
        a.  Virtual MFA devices {e.g. Google Authenticator (works on 1 device at a time) or Authy(works on multiple devices at the same time)}
        b.  Universal 2nd Factor (U2F) security key (e.g.- Yubikey)
        c.  Hardware Key fob MFA Device
            a.  For non-government cloud: Its a key fob provided by Gemalto (Thales)
            b.  For government cloud: Its a key fob provided by surepassid
    
    Q10: How to set up a password policy?
    A10: Following are the steps
        a.  Login to the AWS management console (as a user having administrator access)
        b.  Navigate to IAM Dashboard
        c.  Under Access Management, look for 'Account Settings'
        d.  Click on 'Account Settings' and then click on 'Change Password Policy'
        e.  The next screen will have 'Set Password Policy' as a header with the following options
            1.  Enforce Mininum password length (It has a box to enter the number of characters)
            2.  Require at least one uppercase letter from Latin Alphabet (A-Z)
            3.  Require at least one lowercase letter from Latin Alphabet (a-z)
            4.  Require at least one number
            5.  Require at least on non-alphanumeri character (! @ # $ % ^ & * ( ) _ + - = [] {} | ')
            6.  Enable password expiration
            7.  Password expiration requires administrator reset
            8.  Allow users to change their own password
            9.  Prevent Password reuse
        f.  All the above options are checkboxes, so you can select based on your organization's guidelines
        g.  Click on 'Save Changes'

    Q11: How to add MFA to the root user?
    A11: Once logged in as the root user
        a.  Click on the username on the top right
        b.  Under the options, click on 'My Security Credentials'
        c.  You will be navigated to a different page with the following options
            1.  Password
            2.  Multi-Factor authentication (MFA)
            3.  Access keys (access key ID and secret access key)
            4.  CloudFront key paris
            5.  X.509 certificate
            6.  Account Identifiers
        d.  Select 'Multi-Factor authentication', that will provide you with following three options (radio buttons)
            1.  Virtual MFA Device
            2.  U2F security Key
            3.  Other Hardware MFA Device
        e.  Select 'Virtual MFA Device'
            The following virtual devices are supported
            Authy, Duo Mobile, LastPass Authenticator, Microsoft Authenticator, Google Authenticator

    Q12: What are the minimum roles an IAM user must have to be able to generate their individual access keys?
    A12: Following are the mininum roles
        a.  IAM FullAccess  :   To be able to see the roles and perform actions on individual scope
        b.  IAM UserSSHKeys :   To be able to generate their own individual access keys

        Once the iam user has these roles, then 'Security Crendentials' tabe under 'Users' will show up without any errors
        and the 'Create aceess key' option will be enabled.
    
    Q13: How to create an access key for an IAM user to be used with CLI or SDK?
    A13: Once you have the required roles (IAM FullAccess and IAM UserSSHKeys),
        a.  Click on the Top right of the aws management console on your username
        b.  Click on 'Security Credentials', it will take you to 'My Security Credentials' page
        c.  Scroll towards the bottom and look for 'Access Keys'
        d.  click on 'Create Access Keys', it will display the following options (radio buttons)
            1.  Command Line Interface (CLI):   {You plan to use this access key to enable the AWS CLI to access your account}
            2.  Local code: {You plan to use this access key to enable application code in a local development environment to access your AWS account}
            3.  Application running on an AWS compute service:  {You plan to use this access key to enable application code running on an AWS compute 
                service like Amazon EC2, Amazon ECS, Amazon Lambda to access your account}
            4.  Third Party service:    {You plan to use this access key to enable access for a third party application or service that monitors or 
                manages your AWS}
            5.  Application running outside AWS:    {You plan to use this access key to enable an application running on an on-premise host, or to 
                use a local AWS client or third party aws plugin}
            6.  Other:  {Youyuse case is not listed here.}    
        e.  With selection of any option, AWS will provide a potential recommendation.
        f.  Their is an optional step to create a tag to understand what this key will be used for.
        g.  On the 'Retrieve access keys' page: You will see an option to download the access keys via a 'csv' file and also, save it from the GUI
        h.  Click on 'Done' and you will be navigated back to the 'User page'
        i.  Under the 'Access Keys' section, you will see the key with the tag and statu as 'Active'
        j.  If you wish to generate a new access keys, you can do that, but only one access key can be active at one time.
        k,  Their is an option to delete the keys, if you feel the need to do so.
    
    Q14: What are the minimum policies to have on the role or the user to be able to access AWS Cloud Shell?
    A14: Their is only one permission which must be assigned to the role or the user to have them able to access AWS Cloud Shell
         The policy name is - AWS CloudShellFullAccess
         Once the policy is attached to the user or the role, the cloud shell will work for the user.

    Q15: What are IAM roles for services?
    A15: So far, we have dealt with a username accessed by a physical person to be able to perform certain checks or tasks. The next category is to 
    have applications talk to each other (similar to one microservice talking to another). For this to happen, the service which is trying to perform 
    an action on another service must have the permission to do. This is managed by IAM roles for the service. 
    Following are few examples:
        a.  EC2 Instance roles
        b.  Lambda Function roles
        c.  Roles for CloudFormation
    
    Q16: How to create an IAM role for a service?
    A16: Login to the AWS management console with a User who has administrative access.
        a.  Navigate to the IAM dashboard by simply searching IAM on the search bar
        b.  From IAM dashboard, navigate to 'Roles' under 'Access Management'
        c.  If this is the first time you are trying to create a role, you will see following roles pre-existing
            1.  AWS ServiceRoleForSupport
            2.  AWS ServiceRoleForTrustedAdvisor
        d.  Click on 'Create Role'
        e.  Next Page will have a header 'Select Trusted Entity' with the following options (radio buttons)
            1.  AWS Service:    {Allows AWS Services like EC2, Lambda or others to perform actions in this account}
            2.  AWS Account:    {Allows entities in other AWS accounts belonging to you or a 3rd party to perform actions in this account}
            3.  Web Identity:   {Allows users federated by the external web identity provider to assumer this role to perform actions in this account}
            4.  SAML 2.0 Federation:    {Allows users federated with SAML 2.0 from a corporate directory to perform actions in this account}
            5.  Custom Trust Policy:    {Create a custom trust policy to enable others to perform actions in this account}
        f.  For ease of understanding, lets create an 'AWS Service' role for an EC2 instance to read data in IAM
        g.  On the 'Add Permissions' page for this new role, search and select 'IAMReadOnlyAccess'
        h.  On the next page, provide a role name and click next
        i.  Once the role is created, it will show up on the 'Roles' page

    Q17: What are IAM security tools?
    A17: Their are two security tools
        a.  IAM Credentials Report
            This is at the account-level
            Its a report that lists all your account uders and the status of their various credentials
        
        b.  IAM Access Advisor
            This is at the user-level
            Access Advisor shows the service permissions granted to a user and when those services where last accessed
            This information can be utilized to revise the policies and implement 'principle of least privilege'

    Q18: How to generate a IAM Credentials Report?
    A18: Login to the AWS management console with a User who has administrative access.
        a.  Navigate to the IAM dashboard by simply searching IAM on the search bar
        b.  On the IAM dashboard (Left vertical bar), look for 'Credentials Report' under 'Access Report'
        c.  Click on 'Crendentials Report' and then 'Download credentials report'
        d.  The crendentials report has the following columns (per user on the account includinr <root>)
            1.  user
            2.  arn
            3.  user_creation_time
            4.  password_enabled
            5.  password_last_used
            6.  password_last_changed
            7.  password_next_rotation
            8.  mfa_active
            9.  access_key_1_active
            10. access_key_1_last_rotated
            11. access_key_1_last_used_date
            12. access_key_1_last_used_region
            13. access_key_1_last_used_service
            14. access_key_2_active
            15. access_key_2_last_rotated
            16. access_key_2_last_used_date
            17. access_key_2_last_used_region
            18. access_key_2_last_used_service
            19. cert_1_active
            20. cert_1_last_rotated
            21. cert_2_active
            22. cert_2_last_rotated

    Q19: How to navigate to Access-Advisor?
    A18:  Login to the AWS management console with an IAM user
        a.  Navigate to the IAM dashboard by simply searching IAM on the search bar
        b.  On the IAM dashboard (Left vertical bar), look for 'Users'
        c.  Click on users and then click on 'Access Advisor' on the page.
        d.  Access-Advisor tells you  - 'Which particular service was accessed when based on what policy'
        e.g.
            Service         Policies Granting Permissions       Last Accessed
            AmazonEC2       AmazonEC2FillAccess and 1 More      Today
            AWS Cloudshell  AWSCloudShellFullAccess             Today


    IAM Guidelines & Best Practices
    a.  Dont Use the root account except for AWS account setup
    b.  One physical user = one AWS user
    c.  Assign users to groups and assign permissions to group
    d.  Create a strong password policy
    e.  Use and enforce the use of MFA
    f.  Create and use Roles for giving permissions for AWS services
    g.  Use Access Keys for Programmatic Access (CLI / SDK)
    h.  Audit permission of your account with the IAM credentials report
    i.  Never share IAM users and Access keys.


    IAM Summary:
    a.  USERS:      Mapped to a physical user, has a password for AWS console
    b.  GROUPS:     Contains Users only
    c.  POLICIES:   JSON document that outlines permissions for users or groups
    d.  ROLES:      For EC2 instances or AWS services
    e.  SECURITY:   MFA + Password Policy
    f.  ACCESS KEYS: Access AWS using the CLI or SDK
    g.  Audit:      IAM Credentials and IAM Access Advisor
    h.  Maximum Policies that can be associate with a USER Group is : 10

-----------------------------------------------------------------------------------------------------------------------------------------------------------
AWS - CLI & Cloud Shell
-----------------------------------------------------------------------------------------------------------------------------------------------------------
    
    
    Q01: In how many ways, can the users access AWS?
    A01: Their are 3 ways by which users can access AWS
        a.  AWS Management Console (protected by password + MFA)
        b.  AWS Command Line Interface (CLI): protected by access keys
        c.  AWS Software Development Kit (SDK): for code: protected by access keys
    
    Note: 
    Access keys are generated using the AWS console
    Users manage their own access keys (access keys id ~= username; secret access key ~= password), so every IAM user can have their own keys

    Q02: How to configure AWS CLI on windows?
    A02: Following are the steps:
        a.  Download the AWSCLI version for windows and install on your machine.
        b.  To verify, if it was installed correctly, you can type 'aws --version' on the windows command prompt & the output should look like the following

            C:\Users\samarth>aws --version
            aws-cli/2.9.19 Python/3.9.11 Windows/10 exe/AMD64 prompt/off
        c.  Now, its time to configure aws cli on the windows machine, you will neeed the following
            a.  Your access key
            b.  Your secret key
            c.  Region (select the one closest (for training purposes))
        d.  Execute 'aws configure' on the windows command prompt

            C:\Users\samarth>aws configure
                AWS Access Key ID [None]: MyAccessKey
                AWS Secret Access Key [None]: MySecretKey
                Default region name [None]: us-east-1
                Default output format [None]:
            C:\Users\samarth>
        6.  Now the AWS CLI is configured, we run the following command to see, if it returns an output.

            C:\Users\samarth>aws iam list-users

            {
                "Users": [
                    {
                        "Path": "/",
                        "UserName": "Samarth-Admin",
                        "UserId": "AIDA*************",
                        "Arn": "arn:aws:iam::*************:user/Samarth-Admin",
                        "CreateDate": "2023-01-29T15:31:41+00:00",
                        "PasswordLastUsed": "2023-01-29T16:36:37+00:00"
                    },
                    {
                        "Path": "/",
                        "UserName": "Samarth-Developer",
                        "UserId": "AIDA*************",",
                        "Arn": "arn:aws:iam::*************:user/Samarth-Developer",
                        "CreateDate": "2023-01-29T13:59:14+00:00",
                        "PasswordLastUsed": "2023-01-29T16:35:12+00:00"
                    }
                ]
            }
            C:\Users\samarth>
        
    Important Note: AWS-CLI is just another method of accessing the data, the data shows will always be same across management console and CLI
    For e.g.:- If we go ahead and remove the policy 'IAM FullAccess' from the group 'AWS-Developer', which IAM user 'Samarth-Developer' is a part of,
    And then execute the same command (aws iam list-users) from windows command prompt, their will be no output, same can be validated by going to the 
    Management console, under users page, you will see 'You need Permissions' message.

    Q03: What is AWS CloudShell?
    A03: AWS CloudShell is a browser-based shell that makes it easier to securely manage, explore, and interact with your AWS resources. 
    CloudShell is pre-authenticated with your console credentials.

    {So if you are logged in as 'samarth-developer', the same credentials will be used by default}
    For an IAM user to be able to use the AWS CloudShell, the user must have the 'AWS CloudShellFullAccess' permission policy attached to the user 
    id either by a group policy or a user policy.

    Note: The username for cloudshell is:- cloudshell-user

            [cloudshell-user@ip-10-0-124-229]$aws iam list-users

            {
                "Users": [
                    {
                        "Path": "/",
                        "UserName": "Samarth-Admin",
                        "UserId": "AIDA*************",
                        "Arn": "arn:aws:iam::*************:user/Samarth-Admin",
                        "CreateDate": "2023-01-29T15:31:41+00:00",
                        "PasswordLastUsed": "2023-01-29T16:36:37+00:00"
                    },
                    {
                        "Path": "/",
                        "UserName": "Samarth-Developer",
                        "UserId": "AIDA*************",",
                        "Arn": "arn:aws:iam::*************:user/Samarth-Developer",
                        "CreateDate": "2023-01-29T13:59:14+00:00",
                        "PasswordLastUsed": "2023-01-29T16:35:12+00:00"
                    }
                ]
            }
            [cloudshell-user@ip-10-0-124-229]$

-----------------------------------------------------------------------------------------------------------------------------------------------------------
Budget and Billing
-----------------------------------------------------------------------------------------------------------------------------------------------------------

    Q01: Can an IAM user access the Billing and Cost Management Dashboard by default?
    A01: No, the only user who can access Billing and Cost Management Dashboard by default is the root user.
    The root user need to provide permisions to IAM user - so that they can also access Billing and Cost information

    Following are the steps for the root user to allow access.
    Note:   This approach only works for an IAM user with Administrator Access
    a.  Login as the root user
    b.  On the top right click on Login name and then click on 'Account'
    c.  Once navigated to the new page, look for 'IAM User and Role Access to Billing Information'
    d.  Click on 'Edit' and then 'Activate IAM Access'
    e.  Refresh the page and now log in as the IAM user with Administrator Access
    f.  Click on the top right on login name and then click on 'Billing Dashboard'
    h.  Since the IAM access has been activated, this IAM user will now be able to see the AWS Billing Dashboard

    To provide 'AWS Billing Dashboard' Access to a non-administrative IAM user, the steps are different
    a.  Login as the root user
    b.  Navigate to the IAM dashboard by simply searching IAM on the search bar
    c.  Under 'Access Management' click on 'User Groups'
    d.  Click the group, to which the non-administrative IAM user belongs to
    e.  Click on 'Permissions'
    f.  Search for 'Billing' permission policy and attach this policy to this group.
    8.  Now th 'Non-administrative' IAM User should also have access to the AWS Billing dashboard.


    Q02: How to create a Budget?
    A02: Login to the management console as an Administrative / root user
        a.  On the top right click on Login name and then click on 'Billing Dashboard'
        b.  On the left vertical menu (side bar), click on 'Budgets' under 'Cost Management'
        c.  On the 'Budgets' page, click on 'Create a Budget'
        d.  Their are two budget set up types, 'Use a template (simplified)' and 'Customize (advanced)'
        e.  Select 'Use a Template (simplified)'
        f.  Their are multiple templates, namely (Radio Buttons)
            1.  'Zero spend budget':    {Create a budget that notified you once your spending exceeds $0.01 which is above the AWS free tier limits}
            2.  'Monthly Cost Budget':  {Create a monthly budget that notified you if you exceed, or are forecasted to exceed, the budget amount}
            3.  'Daily Savings Plans Coverage budget':  {Create a converage budget for your savings plans that notifies you when you fall below the 
                defined target}
            4.  'Daily reservation utilization budget': {Ceate a utilization budget for your reservations that notifies you when you fall below the 
                defined target}
        g.  Click on 'Monthly Cost Budget'
        h.  Provide the following values
            1.  Budget Name
            2.  Enter your budgeted amount ($)
            3.  Email Recipients:   {To receive threshold alerts}
        i.  Once the budget is created, 

-----------------------------------------------------------------------------------------------------------------------------------------------------------
AWS-EC2: Elastic Compute Cloud
-----------------------------------------------------------------------------------------------------------------------------------------------------------
EC2 is the most popular offerting of AWS's offering
EC2 = Elastic Compute Cloud is an IaaS (Infrastructure as a Service)

It has the following capabilities
    a.  Renting Virtual Machines (EC2 - Elastic Compute Cloud)
    b.  Storing Data on Virtual Drives (EBS - Elastic Block Storage)
    c.  Distributing Load Across Machines (ELB - Elastic Load Balancer)
    d.  Scaling the services using an auto-scaling group (ASG - Auto Scaling Group)
Knowling EC2 is the fundamental to understand how the cloud works

EC2 Sizing & Configuration options
    a.  Operating Systems Supported: Linux, Windows or MAC OS
    b.  How much compute power and cores: (CPU)
    c.  How much random access memory (RAM)
    d.  How much storage space
        1.  Network Attached (EBS [Elastic Block Storage] & EFS [Elastic File System])
        2.  Hardware (EC2 Instance Store)
    e.  Network Card: Speed of the card, Public IP Address
    f.  Firewall Rules: Security Group
    g.  Bootstrap Script (Configure at first launch): EC2 User Data

EC2 User Data
    a.  it is possible to bootstrap our instances using an EC2 User Data Script
    b.  Bootstrapping means launching commands when the machine starts
    c.  These scripts are executed only the first time the instance boots.
    d.  EC2 User Data is used to automate boot tasks such as:
        a.  Installing Updates
        b.  Installing Software
        c.  Downloading common files from internet
        d.  Any specific scripts that you may want to execute only when machine boots.
    Special Note: Anything that you run as EC2 User data will be executed as a 'root' user.

    Q01: What are the different types of EC2 Instance Types?
    A01: Their are 7 different types of EC2 Instance types, namely:
        a.  General Purpose (GP)
        b.  Compute Optimized
        c.  Memory Optimized
        d.  Accelerated Computing
        e.  Storage Optimized
        f.  Instance Features
        g.  Measuring Instance Performance
    Special Note: Site to compare all instances : https://www.ec2instances.info
    
    Q02: How to read the naming convention of an EC2 instance?
    A02: For example, the EC2 instance you are working with is m5.2xlarge, here's how to read it
        a.  m:  Instance Class
        b.  5:  Generation (AWS improves the generation over time)
        c.  2xlarge:    Size with in the instance class (more memory , more CPU)
    
    Q03: Explain the characteristics of EC2 Instance type: General Purpose
    A03: General Purpose instance types are great for
        a.  Diversity of workloads, such as web servers or code repositories
        b.  These provide a balance between, Compute, Memory and Networking
    
    Q04: Explain the characteristics of EC2 Instance type: Compute Optimized
    A04: Compute Optimized instance types are great for
        a.  Batch processing workloads
        b.  Media Transcoding
        c.  High Performance Web servers
        d.  High Performance computing (HPC)
        e.  Scientific modeling and Machine Learning
        f.  Dedicated gaming servers.
    Special Note: The compute optimized instances starts with the alphabet 'C'
    e.g.    : C6g, C6gn, C5, C5a, C5n, C4

    Q05: Explain the characteristics of EC2 Instance type: Memory Optimized
    A05: Memory Optimized instance types are great for
        a.  High prformanc, relational or non-relational database
        b.  Distributed web scale cache stores
        c.  In-memory databases optimized for BI (business intelligence)
        d.  Applications performing real-time processing of big unstructured data
    Special Note: The memory optimized instances starts with 'R', 'X', 'z' and 'High Memory'. Here 'R' represents 'Ram'

    Q06: Explain the characteristics of EC2 Instance type: Storage Optimized
    A06: Storage Optimized instances are great for 'storage intensive' tasks that require high, sequential read and write access to large data sets 
    on local storage
        a.  High frequency online transaction processing (OLTP) Systems
        b.  Relational & No-SQL databases
        c.  Cache for in-memory databases (for example, Redis)
        d.  Data Warehousing applications
        e.  Distributed file Systems

    Q07: What is an AWS security group?
    A07: Security groups are fundamental of network security in AWS. They control how traffic is allowed into OR out of EC2 Instances.
        a.  Security Groups only contain allow rules
        b.  Security Group rules can reference by IP Address or by security group
        c.  Security groups are acting as a 'Firewall' on EC2 instanes. They regulate the following:
            1.  Access to ports
            2.  Authorized IP Ranges - IPv4 and IPv6
            3.  Control of inbound network (from other/outside to the instance)
            4.  Control of outbound network (from the instance to other/outside)
        
        Characteristics of a Security Group
        a.  A single security group can be attached to multiple instances. Also, one instance can have many security groups attached to it.
        b.  A security group is locked to a region-and-VPC combination. A security group created in VPN01ABC in US-EAST-2 will not be available in a 
            different Region-VPC combination
        c.  A security group resides 'outside' the EC2 instance, if the traffic is blocked, and EC2 instance will not even see it.
        d.  It's good to maintain one separate security group for SSH Access
        e.  All inbound traffic is 'BLOCKED' by default
        f.  All outbound traffic is 'AUTHORIZED' by default

        Special Note:
        a.  If your application is not accessible (TIME OUT), then its a 'security group'issue
        b.  If your application gives a 'connection refused' error, then its an application error or its not launched.

    Q08: What is an security group referencing in AWS?
    A08: Assume the following sceario:
        a.  You have an EC2 instance with Security Group A attached to it
        b.  This security group A basically authorizes inbound traffic which are part of security group B and C
        c.  Now if you have another EC2 instance which has security group B attached to it, then this will enable the 2nd EC2 instance to be able 
            to connect to the first EC2 instance on the specific port (allowed by the inbound rule in security group A)
        d.  Now if you have a third EC2 instance which has security group C attachedto it, then this will enable the 3rd EC2 instance to be able 
            to connect to the first ES2 instance on the specific port (allowed by the inbound rule in security group A)
        e.  This internal communication between EC2 instances is simply possible because the Security Group A authorized the inbound traffic from 
            security group B and C
    
    Q09: What are the classic ports to know?
    A09: Following are the classic port numbers
        a.  22 = SSH (secure shell): Login to the Linux instance
        b.  21 = FTP (File transfer protocol): Upload files into a file share
        c.  22 = SFTP (Secure file transfer protocol): Upload files using SSH
        d.  80 = HTTP - Access unsecured websites
        e.  443 = HTTPS - Access secured websites
        f.  3389 = RDP (Remote Desktop Protocol) - Login to windows instance.

    Q10: How to change the file permissions for .ppk file in windows?
    A10: While the chmod command works in Linux or Mac, windows doesnot have any such command available. Here's how you change the permissions
        a.  Right click on the file and go to properties and then security.
        b.  Under security click on 'Advanced'
        c.  Click on 'Disable Inheritence' and then click on 'Convert inherited permissions to explicit permissions on this object'
        d.  Then under 'Principal' click on 'System' and remove this user. Do the same for 'Administator' user.
        e.  Once the other users are removed, only the actual user will have access to the .ppk file.
        f.  This process is similar to chmod 400 filename in Mac or Linux.
    
    Q11: What is EC2 Instane connect?
    A11: Once the EC2 instance is created, 'Instance Connect' feature allows you to connect to this instance like a putty session on a 
        web-broswer. For an IAM user to be able to use 'Instance Connect' feature, the IAM user must have 'EC2InstanceConnect' policy 
        attached to the user either as an 'Inline Policy' or via a group, which the IAM user is a part of.
    
    Q12: Do you need to upload your .ppk file to connect to your EC2 instance when using 'Instance Connect'?
    A12: No, we do not need to upload our .ppk file to connect to our EC2 instance using 'Instance Connect'
        AWS, creates a temporary .ppk file to connect to your EC2 instance, when the connection initiated via 'Instance Connect'
    
    Q13: What will happen, if you remove the 'inbound rule' for port 22 and try to connect to your EC2 instance, via 'Instance Connect'?
    A13: We will not be able to connect to our EC2 instance, via any method utilized SSH (Instance Connect, Putty, Command Promprt, Powershell).
        Since the port 22 is removed / not added to the inbound rules in the security group.
    
    Q14: Does the EC2 instance have 'AWS-CLI' pre-installed?
    A14: Yes, the EC2 instance have AWS-CLI preinstalled, & this can be validated by connecting to the instance via Instance Connect & execute the following 
        aws --version

        [ec2-user@ip-100-1-1-0 /]$ aws --version
        aws-cli/1.18.147 Python/2.7.18 Linux/5.10.162-141.675.amzn2.x86_64 botocore/1.18.6
        [ec2-user@ip-100-1-1-0 /]$ 
    
    Q15: Can you run, AWS-CLI commands on EC2, when connected via Instance Connect?
    A15: Yes, we can run AWS-CLI commands on EC2 instance, even when connected via Instance Connect.

        [ec2-user@ip-100-1-1-0 /]$ aws iam list-users
        Unable to locate credentials. You can configure credentials by running "aws configure".
        [ec2-user@ip-100-1-1-0 /]$

    Q16: Should you perform 'aws configure' on EC2 instance?
    A16: In order to run AWS-CLI commands directly on the EC2 instance, rather than performing 'aws configure' on the instance, one should use, 
        IAM roles. The reason to NOT configure your 'access-key' and 'secret-key' on the EC2 instance is, anybody who is connected to the EC2 
        instance can read the values of your 'access-key' and 'secret-key' there by compromising your security and profile.

    Q17: If 'aws configure' on an EC2 instance is a NO-NO, how do you handle this situation?
    A17: The recommended solution for this is, to use IAM roles.
        To use IAM roles for EC2 instance to run aws-cli commands, perform the following
        a.  Go to your EC2 dashboard and click on the instance name
        b.  On the bottom half section of the page, click on 'Security'
        c.  Under the 'Security Details' section, you will 'IAM Role' but no permission policy attached to it.
        d.  Now on the top half of the page, you will see 'Actions'
        e.  Click on 'Actions' then, 'Security' then 'Modify IAM Role'
        f.  This will let you
            1.  Either create a new role for the task or action you are interested in.
            2.  If you have existing role created, which would suffice for your task, select it from the drop down menu.
                {For e.g. I created an IAM role to 'Read-IAM-Data' for 'EC2'}
        g.  Click on 'Update IAM Role'
        i.  Now, if you go back to the EC2 (via instance connect), you should be able to run the aws cli command (aws iam list-users) and see the output
    
    Q18: Explain EC2 Instance Purchasing options?
    A18: Following are the EC2 instances purchasing options.
        a.  ON-DEMAND Instances : These are good for short workloads and have predictable pricing
        b.  RESERVED Instance   : Should be for a minimum of one year
            1.  Reserved Instances: These are good for longer workloads (for e.g. Database)
            2.  Convertiable Reserved Instances: Long workloads with flexible instances
            3.  Scheduled Reserved Instances: Example every Thursday between 3 and 6 PM
        c.  SPOT Instances  : Short workloads, Cheap and can lose instances (Less reliable)
        d.  Dedicated Hosts : Book an entire physical server, controlled / targetted instance placement.

    Q19: Explain the characteristics of EC2 - On-demand Instances?
    A19: EC2 On-Demand instance works on - 
        a.  Pay for what you use.
            1.  For Linux Machines:- These are charged for per second billing, after the first minute
            2.  For Other Machines:- These are charged for per hour billing
        b.  These instances have the HIGHEST cost, but have no upfront payment.
        c.  Their is no long term commitment for these type of instances.

        These are recommended for : SHORT-TERM and UN-INTERRUPTED workloads, where you cannot predict the behaviour of the application

    Q20: Explain the characteristics of EC2 - Reserved Instances?
    A20: EC2 - Reserved Instances, provide up to 75% discount when compared with On-Demand instances.
        a.  The reservation period for these instances is between 1 and 3 years, bigger the duration, bigger will be the discount
        b.  Purchasing options also have three options
            1.  No Upfront cost, meaning monthly payments
            2.  Partial upfront cost, will get you some discount.
            3.  All upfront cost, will get you even bigger discount.
        
        Their are 3 types of reserved instances
        a.  Reserved Instances:
            For these ones, you must reserve a specific instance type (t2.micro, c5.large etc) and you cannot change the instance after selection
            These are recommended for steady state usage applications, for e.g. a Database

        b.  Convertible Reserved Intances:
            For these ones, you can change the selected instance type. For example c5.large to c5.2xlarge
            These provide upto 54% discount

        c.  Scheduled Reserved Instances: 
            These are available for the time duration (Fraction of Day/ Week/ Month) you reserved them.
            But the commitment should still be between 1-3 years.
    
    Q21: Explain the characteristics of EC2 - SPOT Instances?
    A21: These instances can
        a.  Get you a discount of upto 90% when compared with On-Demand instances.
        b.  You can lose them, at any point in time, if your max price is less than the current spot price. The current spot price keeps on changing. 
            (bidding fashion)
        c.  This is the MOST cost effective instance in AWS.
        
        These instances are recommended for, tasks which are resilient to failure
        a.  Batch Jobs
        b.  Data Analysis
        c.  Image processing
        d.  Any distributed workloads
        e.  Workloads with a flexible start and end time

        These instances are NOT recommended for :- Critical Jobs or Databases.
    
    Q22: Explain the characteristics of EC2 - DEDICATED Instances?
    A22: AWS EC2 Dedicated instances comprises of host, which is a physical server with the EC2 instance capacity fully dedicated to your use.
        Dedicated hosts can help you adress the following
        a.  COMPLIANCE Requirements
        b.  Reduce cost by allowing you to use your existing server bound licenses.

        These are allocated for a 3 year reservation and are more expensive.
        These are useful for:
            a. Softwares that have complicated licensing model (BYOL - Bring your own license)
            b. Organizations with Strong compliance needs.
    
    Q23: Explain the Similarities and difference between Dedicated Hosts and Dedicated Instances?
    A23: Here are the Details
        a.  Similarities
            1.  Both Dedicated Instance and Dedicated hosts, Enables the use of dedicated physical server
            2.  Both Dedicated Instance and Dedicated hosts, have automatic instance placement
        b.  Differences
            1.  Dedicated Instance have Per-Instance-Billing, while Dedicated hosts have Per-Host-Billing
            2.  Dedicated Hosts have:
                i.  Visibility of Sockets, Cores and Hosts ID
                ii. Targeted Instance placement
                iii.Affinity between host and instance
                iv. Add capacity using an allocation request.

-----------------------------------------------------------------------------------------------------------------------------------------------------------
AWS-EBS: Elastic Block Store
-----------------------------------------------------------------------------------------------------------------------------------------------------------

    Q01: What's an EBS volume?
    A01: An EBS volumn is a NETWORK Drive (like a network usb stick) that you can attach to your instance while they run.
        It allows the instances to persist data, even after their termination, which means, if take a snapshot of the volume before the instance was 
        terminated. You can utilize the snapshot to retain the data and a new EBS volume can be used on a new EC2 instances with the old data.
        a.  EBS volumes can be mounted to only one instance at a time (CCP-Level), and one instance can have multiple EBS volumes to it.
            Their is an 'multi-attach' functionality for EBS volumes, but that is more advanced
        b.  When an EC2 instance is created, an EBS volume is attached to it, for the boot.
        c.  EBS volumes are bound to a specific availiability zone, that means once created in a specific availiability zone it cannot be utilized in 
            another zone

        Free-Tier: 30 GB of free EBS storage of type (General Purpose SSD) or magnetic per month

        Special Notes:
            1.  Its a network drive, i.e. Not a Physical Drive
                a.  It uses the network to communicate with the instance, which means there might be a bit of latency.
                b.  It can be detached from an EC2 instance and attached to another one quickly
            2.  Its locked to an Availiability Zone (AZ)
                a.  An EBS volume in us-east-1a cannot be attached to us-east-1b
                b.  To move a volume across, you first need to snapshot it
            3.  Have a provisioned capacity (size in GBs, and IOPS)
                a.  You get billed for all the provisioned capacity
                b.  You can increase the capacity of the drive over time
            4.  An EBS volume can be created standalone and not be attached to an EC2 instance, this is possible.

        Important: How to mount additional EBS volumes to your EC2 instance.
        https://devopscube.com/mount-ebs-volume-ec2-instance/

        EBS - Delete on Termination attribute
            1.  The volume type = Root, attached to the EC2 instance has an attribute 'Delete On Termination' which is 'Checked' by default.
                : Which means, when the instance is terminated the 'root' volume will be deleted.
                This attribute is modifiable, and if you want, you can preserve the root volume.
            2.  The volume type = EBS, attached as an EBS volume to the EC2 instance, also has the attribute 'Delete On Termination' which is NOT 
                'Checked' by default. And as mentioned earlier, this attribute is modifiable.
                : Which means, when the instance is terminated the 'EBS' volume will not be deleted.

            : This attribute can be controlled by the AWS console / AWS CLI.
        
        USECASE: How to perserve the root volume when instance is terminated.
    
    Q02: What is EBS Snapshots?
    A02: EBS Snapshots are used to
        a.  Maske a backup (snapshot) of your EBS volume at a point in time
        b.  Not necessary to detach a volume to do snapshot, but recommended
        c.  Copy snapshots across AZ or Region.
    
    Q03: How to create a snapshot?
    A03. Login to the EC2 dashboard and then follow these steps:
        a.  On the left side vertical menu, look for 'Elastic Block Store'
        b.  Under 'Elastic Block Store' click on 'Volume'
        c.  On the new page that opens, you will see the EBS volumes that are created / attached to the EC2 instance.
        d.  Select the volume you wish to create a snapshot for.
        e.  Click on Actions menu on the same page (horizontal bar) and click on 'Create Snapshot'
        f.  On the next screen, provide a description for the snapshot, for identification. You can add tags as well.
        g.  And then click on 'Create Snapshot'
        h.  You will see a message on the screen - 'Create Snapshot Request Succeeded'
        i.  Now click on 'Snapshots' under 'Elastic Block Store', and you will see the newly created snapshot


        Special Note: Snapshots are created in 'Regions', so these can be copied to 'Another Region' or 'Another AZ in the same region'
    
    Q04: How to copy a snapshot to another region
    A04: Login to the EC2 dashboard and then follow these steps:
        a.  On the left side vertical menu, look for 'Elastic Block Store'
        b.  Under 'Elastic Block Store' click on 'Snapshots'
        c.  Assuming you have a snapshot created earlier (which will be listed in this window)
        d.  Click on 'Actions' menu, then click on 'Copy'
        e.  On the 'Copy Snapshot' window, select the 'Destination Region' and provide/select the description and click copy.
        f.  The snapshot will then be copied to the destination region.
    
    Q05: How to create a volume based on a snapshot from one region to another.
    A05: Login to the EC2 dashboard and then follow these steps:
        a.  On the left side vertical menu, look for 'Elastic Block Store'
        b.  Under 'Elastic Block Store' click on 'Snapshots'
        c.  Assuming you have a snapshot created earlier (which will be listed in this window)
        d.  Click on 'Actions' menu, then click on 'Create Volume'
        e.  One the 'Create Volume' window. provide the following
            1.  Volume Type: Its a dropdown list, you can select whatever is your Requirements
            2.  Size in GBs
            3.  Availiability Zone: Its a drop down list of AZs in your current region
            4.  Encryption: Its a checkmark
        f.  Click on create volume
        g.  Now that the EBS volume has been created, click on 'Volume' under 'Elastic Block Store'
        h.  You should be able to see the new volume in the new availiability zone.

        This is how you take a snapshot and copy the data from one AZ to Another AZ in the same region.

    Q06: What is an AMI?
    A06: AMI is Amazon Machine Image
        a.  AMIs are a customization of an EC2 instance.
            1.  You add your own software, configuration, OS , monitoring etc.
            2.  Faster Boot / Configuration time because all of your software is pre-packaged
        b.  AMI are built for SPECIFIC region (And can be copied across regions)
        c.  You can launch EC2 instances from:
            1.  A public AMI: Provided by AWS
            2.  Your Own AMI: You make and maintain them yourself.
            3.  AWS Marketplace AMI: An AMI someone else made(and potentially sells)
    
    Q07: How to create an AMI from an EC2 Instance?
    A07: Start an EC2 instance with any specific AMI, then customize it (add JDK, Tomcat, DB etc) and then stop the instance.
        Then we will build the AMI from this image (This will also create EBS snapshots, since attached EBS will be a part of the AMI)
        Now this modified AMI can be used to launch new instance, with the pre-packaged software.

        Following are the steps:
        a.  Assuming you have done all the required changes to the current EC2 instance
        b.  Right click on the running 'EC2' instance and then click on 'Image and Templates'
        c.  Then click on 'Create Image'
        d.  Provide a name to the image
        e.  You will notice, the image creation has automatically select the EBS volume used to boot this current EC2 instance, with the 
            attribute (Delete on Termination) enabled.
        f.  Their are two following options for tags {Radio Buttons}
            1.  Tag image and snapshots together
            2.  Tag image and snapshots separately
        g.  Click on 'Create Image' on this page.
        h.  The image will be created successfully.

    Q08: How to Launch a new EC2 instance based on 'Created AMI'?
    A08: Once you have successfully created your own modified AMI image, the image should show up under 'Images' in EC2 dashboard
        {Left Vertical Menu}
        a.  On the EC2 dashboard, click on Launch Instances.
        b.  On the next step 'Choose an Amazon Machine Image (AMI), click on 'My AMIs' on the left vertical menu
        c.  Your modified AMI should be visible here, select it.
        d.  Select the instance type
        e.  Configure the security group
        f.  Review the launch instance and then click on 'Launch Instance'
    This is how you launch an EC2 instance based on the 'Created AMI'

    Q09: What is an EC2 Instance Store?
    A09: EBS volumes are network drives with good, but 'Limited' Performance.
        If you need a 'High-Performance hardware disk' use EC2 Instance Store

        EC2 Instance Store has the following characteristics.
        a.  Better I/O Performance
        b.  EC2 Instance Store lose their storage if they are stopped (ephemeral) {More like RAM}
        c.  This is good for Buffer / Cache or temporary content.
        d.  Risk of Data Loss, if the hardware fails
        e.  Back and Replication are Your responsibility
        f.  The instances usually start with 'i' in the naming conventions (e.g. i3.large, i3en.metal, i3.metal, i3.8xlarge)

    Q10: Explain the types of EBS Volumes?
    A10: Their are total 6 types of EBS volumes for now, following are the categories.
        a.  gp2 / gp3 (SSD) : General purpose SSD volumes that balance price and performance for a variety of workloads
        b.  io1/ io2 (SSD)  : Highest performance SSD volume for mission-critical low-latency or high-throughput workloads
        c.  st1 (HDD)   : Low Cost HDD volume designed for frequently accessed, throughput-intensive workloads.
        d.  sc1 (HDD)   : Lowest cost HDD volume designed for less frequently accessed workloads.
    
    EBS volumes are characterized in Size
        a.  By Size
        b.  By throughput
        c.  By IOPS (I/O operations per second)
    When in doubt, always use AWS documentation.

    Special Note: For EC2 instance, only gp2/gp3 and io1/io2 EBS volumes can be used for boot volumes.

    Q11: Explain the characteristics of General Purpose SSD EBS volume?
    A11: General Purpose SSDs are
        a.  Cost Effecive Storage, Low-latency
        b.  Used for : System boot volumes, Virtual Desktops, Development and Test environments.
        c.  Size is between: 1GB - 16TB
    
    gp3 is the higher generation of General Purpose SSDs
        gp3:
            1.  Baseline of 3000 IOPS and throughput of 125 MBPS
            2.  Can increase IOPS to 16000 and throughput to 1000 MBPS independently
        gp2:
            1.  Small gp2 volumes can burst IOPS to 3000
            2.  Size of the volume and IOPS are linked, max IOPS is 16000
            3.  IOPS per GB, means at 5334 GB we are at the max IOPS.
    
    Q12: Explain the characteristics of Provisioned IOPS EBS Volume?
    A12: Provisioned IOPS SSDs are good for
        a.  Critical Business applications with sustained IOPS performance
        b.  OR Applications that need more than 16000 IOPS
        c.  Great for database workloads (sensitive to storage performance and consistency)
        d.  Supports EBS multi attach

        io1/io2: size ranges from 4GB to 16TB
            1.  Max provisioned IOPS : 64000 for Nitro EC2 instances & 32000 for other.
            2.  Can increase PIOPS independently from Storage size
            3.  io2 have more durability and more IOPS per GB (at the same price of io1)
        
        Their is a new type of io volume namely io2 Block Express
            1.  Size range is 4GB to 64TB
            2.  Sub-Milisecond latency
            3.  Max PIOPS: 256000 with an IOPS:GB ratio of 1000:1
    
    Q13: Explain the characteristics of HDD EBS volume?
    A13: HDD EBS Volumes
        a. Cannot be a boot volume
        b. Size ranges between 125MB to 16TB
        
        Their are two types of HDD EBS Volumes
        1.  st1: These are throughput optimized HDDs, good for Big Data, Data Warehouses and Log processing workloads.
        2.  sc1: These are cold HHDs, and good for infrequently (archival) accessed data, and has the lowest cost of all.
    
    Q14: What is EBS Multi-Atatch?
    A14: Multi-Attach is a functionality that allows you to "attach one EBS volume to multiple EC2 instances in the SAME AZ."
        This functionality is only available for EBS volumes from the io1/io2 family
        Note:
            1.  Each EC2 instance attached to such an EBS volume has full read and write permissions to the volume
        
        USECASE:
            1.  Applications using this functionality must be able to manage concurrent write operations to the same volume
            2.  Applications using this functionality muse you a filesystem that's cluster aware.
        This functionality will allow the applications to achieve higher application availability in clustered Linux applications.

-----------------------------------------------------------------------------------------------------------------------------------------------------------
AWS-EBS: Elastic File System
-----------------------------------------------------------------------------------------------------------------------------------------------------------

    Q01: What is EFS?
    A01: EFS is Elastic File System.
        a.  Its a Managed FNS (Network File System) that can be mounted to many EC2 instances in the same region.
        b.  EFS works with EC2 instances in multi-AZ.
        c.  Highly available, scalable, expensive (3 times of a gp2)
        d.  Works with 'Pay-per-use' model

        Suppose you have one EFS and three EC2 instances spread across different AZs in the same region.
        All 3 EC2 instances can connect to this EFS via the security group.

        USECASES:
            1.  Can be used in ContentManagement, Web-Serving, Data-Sharing, WordPress
            2.  Uses NFSv4.1 protocol
            3.  Uses security group to control access to EFS
            4.  Compatible only with Linux based AMI {Does not work with Windows}
            5.  Filesystem is encrypted at rest using KMS
        
        Special Note:
            1.  File system scales automatically, pay-per-use, no-capacity-planning.

        EFS - Performance & Storage Classes:
            EFS Scale:
                1.  1000s of concurrent NFS clients, 10GB+ /s throughput
                2.  Grow to petabyte-scale network file system, automatically
            Performance Mode (set at EFS creation time)
                1.  General Purpose (default): Latency Sensitive use cases (Web Server, CMS etc)
                2.  Max I/O - Higher Latency, throughput highly parallel (Big Data, Media Processing)
            Throughput Mode
                1.  Bursting (1TB=50MBPS + Burst of up to 100 MBPS)
                2.  Provisioned: Set your throughput regardless of the storage size, e.g. (1 GBPS for 1 TB Storage)
        
        Related Question:
        Q: If you want to increase the throughput of a very small filesystem then which mode of EFS should be used?
        A: Provisioned Throughput mode.

        Storage Tiers:
            This is a lifecycle management feature for the files, to move the file after 'N' days.
            a.  Standard: For frequently accessed file
            b.  Infrequent Access (EFS-IA): This has a lower price to store, but has a Cost to retrieve the file.
    
    Q02: What is the minimum IAM permission policy that must me attached either to the group or the user to be able to create an EFS?
    A02: The mininum IAM policy required to be able to create an EFS is :- AmazonElasticFileSystemClientFullAccess.
    
    Q03: What is the minimum IAM permission policy that must be attached either to the group or the user to be able to read data from EFS?
    A03: The mininum policy required to be able to read data from EFS is :- AmazonElasticFileSystemReadOnlyAccess.

    Q04: How to create an EFS (Elastic File System)?
    A04: Following are the steps:
        a.  On the AWS management console, search for EFS
        b.  Once navigated to the EFS console, click on 'Create File System'
        c.  On the 'Create File System' dialog, Click 'Customize'
            1.  The name is optional
            2.  And the Default VPS is pre-selected
            3.  Their is a button to 'Create' to use default settings and another one to 'Customize'
        d.  On the new page 'File System Settings'
            1.  The name is optional
            2.  Automatic Backups is 'Checked':
                {Automatically Backs up your file system data. Additional pricing is applied}
            3.  Lifecycle Management
                This is a drop down value with multiple options to move files based on how frequently they are accessed.
                If you select '30 days since last access' then any file which has not been accessed in last 30 days will be moved 
                to EFS-IA (Elastic File System - Infrequent Access Data storage class to save some cost)
            4.  Performance Mode
                i.  General Purpose: Ideal for latency sensitive use-cases like web serving and content management systems.
                ii. Max I/O: Scale to higher levels of aggregate throughput and operations per second.
            5.  Throughput Mode
                i.  Bursting: Throughput scales with file system size
                ii. Provisioned: Throughput fixed at a specified amount. {This is configurable}
            6.  Encryption:
                Enable encryption of data at rest is enabled by default.
        e.  On the new page 'Network Access Settings'
            1.  Virtual Private Cloud (VPC) : Default VPC is pre-selected
            2.  Mount Targets
                Since EFS can work across all AZs in a region, multiple AZs options are available in this section.
                The subnets are pre-selected.
                The default security groups are also selected, and can be MODIFIED. However a security group must be defined for each AZ
                where this particular EFS will be available and accessed.


        f.  File system policy is optional
        g.  Next page is 'Review and Create'
        h.  Click on Create and the EFS file system will be created.

    Q05: How to attach an EFS to multiple EC2 instance in the same region but in different AZs?
    A05: Following are the steps:
        a.  On the AWS management console, search for EC2.
        b.  Once navigated to EC2 dashboard, on the left vertical menu, click on security groups under Network Security
        c.  Create a new security group 'EC2-to-EFS'
            1.  Add a new Inbound rule with 
                TYPE=NFS
                SOURCE=Select the Security Group which has SSH Access at port 22 for EC2.
                        If you dont want to use the existing security grousp with SSH Access, create a new one with specific name
                        and then select that Security Group Here.

                        Special Note: Even though the protocol and port number are same in different security groups. They are still 
                        treated as unique. So, selection of correct security group is very important.
                Click on 'Add Rule' and then click on 'Create Security Group'.
                
        d.  Now go back to your EC2 instances on the EC2 Dashboard and under 'Security' check the 'Security Groups'
        e.  Whatever be the name of this security group (it must be same for all instances which you plan to connect to EFS)
        f.  This should be the same security group, which you will 'Select' as 'SOURCE' for 'EC2-to-EFS' security group.
        g.  Now on the AWS management console, look for EFS and navigate to EFS console.
        h.  You should have an EFS file system created.
        i.  Click on the EFS filesystem and navigate to 'Network'
        j.  Under 'Network' you MUST have 'Mount targets' 'CREATED'. Unless the status created, its not going to work
        k.  if the 'Mount Targets' are not created, check if you have done the correct selection of 'Security Groups' (i.e. 'EC2-to-EFS' SG)
        l.  Once the Mount Targets are created, go ahead and connect to your EC2 instances using the pem/ppk file via SSH
        m.  On each of the instances, create a directory 'efs' this is the directory which we will use as the mount point of EFS.
        n.  Before, we can mount the EFS to 'efs' directory, we need to install the NFS utils packaged
        o.  As root (sudo) - execute: yum install -y amazon-efs-utils
        p.  Once package is installed on the EC2 instances, come back to EFS dashboard and click on the File System that was created
        q.  On the top right you will see an option to 'Attach'
        r.  Use the 'Mount via DNS' option and run the command indicated as - 'sudo mount -t efs -o tls fs-0c621fafa80c68ea6:/ efs'
        s.  In the above command, 'tls' is for encryption and 'fs-0c621fafa80c68ea6' is the filesystem ID. and efs at the end is the mount point name.
        t.  If everything was done correctly, the EFS will be mounted on 'efs' directory as the mount point on EC2 instances.

-----------------------------------------------------------------------------------------------------------------------------------------------------------
EBS vs EFS
-----------------------------------------------------------------------------------------------------------------------------------------------------------
EBS Volumes:
    Characteristics
        a.  Can be attached to only ONE instance at a time
        b.  Are locked at the Availability Zone (AZ) level
        c.  For gp2 SSD volumes: IO increases if the disk size increases
        d.  io1: Can increase IO independently
    
    To Migrate an EBS volume across AZ
        a.  Take a Snapshot
        b.  Restore the snapshot to another AZ
        c.  EBS backups use IO and you shouldn't run them while your application is handling a lot of traffic
    
    Root EBS volumes of instances gets terminated by default (Due to Delete on Termination Attribute), if the ECT instance is terminated


EFS
    Characteristics
        a.  Can be attached to multiple instances at a time
        b.  Are NOT locked at the Availability Zone (AZ) level and can be used across different AZs in a region
        c.  Only supports LINUX instances (POSIX File system)
        d.  EFS has a HIGHER price point than EBS
        e.  You can leverage (EFS-IA: In-frequent Access) for Cost Savings

-----------------------------------------------------------------------------------------------------------------------------------------------------------
ELB : Elastic Load Balancer
-----------------------------------------------------------------------------------------------------------------------------------------------------------
    Q01: What is a load balancer?
    A01: Load balancer are servers that forward the internet traffic to multiple servers (EC2 instances) downstream.
        a.  Load Balancers can scale but not instantaneosuly - contact AWS for a "Warm-Up"
        b.  Troubleshooting an ELB:
            1.  4xx errors are client induced errors
            2.  5xx errors are application induced errors
            3.  Load Balancer Errors 503 means 'at capacity' or no registered target
            4.  If the LB can't connect to your application, check your security groups
        c.  Monitoring an ELB:
            1.  ELB Access logs will log all access requests (so you can debug per request)
            2.  CloudWatch metrics will give you aggregate statistics (e.g; Connections Count)
    

    Q02: Why use a load balancer?
    A02: Following are the reasons for using a load balancer
        a.  To spread the load across multiple downstream instances
        b.  Expose a single point of access (DNS) to your application
        c.  Seamlessly handle failures of downstream instances
        d.  Do regular health checks to your instances
        e.  Provide SSL termination (HTTPS) for your websites
        f.  Enforce stickiness with cookies
        g.  High availability across AZs (Assuming your Loadbalancer is spread across different AZs)
        h.  Separate public facing traffic from private facing traffic.
    
    Q03: Why use an EC2 Load Balancer?
    A03: An ELB (Elastic Load Balacer / EC2 Load Balancer) is a MANAGED load balancer
        a.  AWS guarantees that it will be working
        b.  AWS takes care of upgrades, maintenance, high availability
        c.  AWS provides only a few configuration knobs to the user.
    
    Special Notes:
        1.  Its costs less set up your own load balancer but its lot of effort to set it up
        2.  ELB is integrated with many AWS offerings / Services
    
    Q04: Why are Health Checks important?
    A04: Health checks are crucial for load balancers,and enable them to know if the instances it forwards traffic to are healthy
        (Basically checking, if the instances are available to reply to the requests)
        The health check is done on a port (for e.g. 7066) or a route (/health)
        If the response is not 200 (OK), then the instance is deemed 'Unhealthy' and the Load Balancer will stop sending traffic to this instance
        This health check usually happens usually every 5 seconds, but is a configurable value.
    
    Q05: How many types of Load Balancers are their in AWS?
    A05: AWS has 3 different types of MANAGED load balancers
        a.  CLASSIC Load Balancer:  (v1- Old Generation - 2009)
            This supports: HTTP, HTTPS, and TCP
        b.  Application Load Balancer: (v2- New Generation - 2016)
            This supports: HTTP, HTTPS, WebSocket
        c.  Network Load Balancer:  (v2- New Generation - 2017)
            This supports: TCP, TLS (secure TCP) & UDP
        
        Elastic Load Balancer can be set up as internal (private) ELB or external (public) ELB
    
    Q06: Explain Load Balancer Security Group?
    A06: Following is the explaination

                (HTTPS/ HTTPS from anywhere)        (HTTP restricted to/from ELB)
        USERS   ----------------------------->  ELB ----------------------------->  EC2
                <-----------------------------      <-----------------------------
        
        In this design:
        a.  The Load balancer is exposed to the public internet and hence it can accept incoming traffic at
            Port 80 over HTTP
            Port 443 over HTTPS
            So, the load balancer security will have these two rules (1 for port 80 another for port 443)
                type        :   HTTP
                Protocol    :   TCP
                PortRange   :   80
                Source      :   Custom: 0.0.0.0/0 (Anywhere)

        b.  Now the load balancer needs to forward the incoming traffic to the EC2 instance, so we will need another security group
            That will be used to forward the traffic to EC2
                LoadBalancerProtocol:   HTTP
                LoadBalancerPort    :   80
                InstanceProtocol    :   HTTP
                InstancePort        :   80

        b.  The EC2 instance is only exposed to the load balancer and hence can accespt incoming traffic at
            Port 80 over HTTP only from the LOAD BALANCER SECURITY GROUP
    
    Q07: What is a Classic Load Balancer(v1)?
    A07: Classic Load Balancer are generation 1 load balancers and support HTTP, HTTPS and TCP protocols.
        TCP is a layer4, HTTP and HTTPS are layer7 protocols.
        a.  Health checks are TCP or HTTP based.
        b.  Classic LB provide you with a fixed hostname: e.g; : xxx.region.elb.amazonaws.com
    
    Q08: How to create a CLASSIC load Balancer?
    A08: For creation of CLASSIC load balancer, we will need atleast 2 EC2 instance to be able to see if CLB is forwarding traffic correctly
        a.  Login to the EC2 Dashboard
        b.  Under 'Network & Security' click on 'Security' and create a new 'security-group' with inbound rule to allow http at port 80 from anywhere
        c.  Create two new EC2 instances and select this newly created security as their security group.
        d.  In the left side vertical menu, under 'Load Balancing' click on 'Load Balancers' then click on 'Create Load Balancer'
        e.  select 'Classic Load Balancer' and click on create.
        f.  on the 'Define Load Balancer': Provide a Name to the Load Balancer in the default VPC.
            1. LoadBalancerProtocol:   HTTP
            2. LoadBalancerPort    :   80
            3. InstanceProtocol    :   HTTP
            4. InstancePort        :   80
        g.  Since this will be a public facing ELB, DO NOT select 'Create an internal Load Balancer'.
        h.  On the 'Assign Security Group' select the security group that was create in step (b)
        i.  Since we have HTTP protocol and not HTTPS, AWS will show a warning message.
        j.  On the 'Configure Health Check'
            1. Ping Protocol: HTTP
            2. Ping Port: 80
            3. Ping Path: can be '/' or '/index.html' depending on if you have HTTPD enabled and have a index.html in /var/www/html/index.html
            4. Response Timeout: 5 seconds
            5. Interval: 30 seconds
            6. Unhealthy Threshold: 2 seconds
            7. Healthy Threshold: 10
        k.  Select the instances that you want to map to this classic load balancer.
        l.  Review and create and then 'Create' the Classic Load Balancer.
        
    Q09: What does ELB status 'Out-of-Service' means?
    A09: The status 'Out-of-Service' will be shown on the EC2 dashboard for the ELB, when
        a.  The instance is newly created and the EC2 instances are still being registered with the ELB
        b.  The instance is unhealthy and the healthchecks have failed consecutively.
    
    Q10: What is an Application Load Balancer(v2)?
    A10: Application load balancers operate at layer 7 (HTTP)
        a.  Load Balancing to multiple HTTP applications across machines (called as Target Groups)
        b.  Load Balancing to multiple applications on the same machine (e.g. Containers)
        c.  Support for HTT/2 and WebSocket
        d.  Supports redirects (from HTTP to HTTPS).
        e.  Supports routing based on path in URL (example.com/users & example.com/posts)
        f.  Supports routing based on hostname in URL (one.example.com & other.example.com)
        g.  Supports routing based on query string, headers (example.com/users?id=123&order=false)
    
        Special Note: 
            a.  ALBs are great fit for microservices & container-based applications (e.g; Docker & Amazon ECS), because these have a 
                port mapping feature to redirect to a dynamic port in ECS (Elastic Container Service).
            b.  ALBs also provide a fixed hostname like Classic LBs (XXX.region.elb.amazonaws.com)
            c.  The application servers dont see the IP of the client directly, rather the true information of the clients are in the headers
                1. X-Forwarded-For: ClientIP
                2. X-Forwaded-port: Port
                3. X-Forwaded-Proto: Protocol
            d.  Latency for ALBs is around 400ms
        
        ALBs can route traffic to: (IP Addresses - MUST BE PRIVATE IPS)
            a.  EC2 instances (can be managed by an Auto Scaling Group) - HTTP
            b.  ECS tasks (managed by ECS itself) - HTTP
            c.  Lambda Functions - HTTP Request is translated into a JSON format.
            d.  Multiple Target groups, and health checks are at the target level.

    Q11: How to create a Application Load Balancer?
    A11: Following are the steps:
        a.  Login to the EC2 Dashboard
        b.  In the left side vertical menu, under 'Load Balancing' click on 'Load Balancers' then click on 'Create Load Balancer'
        c.  select 'Application Load Balancer' and click on create.
        d.  On the 'Configure Load Balancer' - Basic configuration
            1.  Provide a name for the application load balancer
            2.  Scheme :    Internet-Facing
            3.  IP Address Type: IPv4
            4.  Listeners : A listener is a process that checks for connection requests, using the protocol and port that is configured
                i.  Load Balancer Protocol: HTTP
                ii. Load Balancer Port: 80
            5.  For Availability Zone:
                i.  Select the default VPC
                ii. Select the AZs which you want to configure for the ALB.
            6.  On the 'AWS global accelerator, do noting.
        e.  On the 'Configure Security Settings'
            Since we used HTTP port instead of HTTPS: AWS will show a security warning.
            Now, you can either create a new security group that will accept traffic from 'Anywhere' to ALB-port 80 with HTTP protocol.
            OR, if you already have one, you can use it. Make a note, which security group was configured.
        f.  On the 'Configure Routing' page
            1.  Target Group:   New Target Group
            2.  Name        :   Provide a target group name
            3.  Target Type :   We will select 'Instance' since we will map EC2 instance to this ALB
                            :   Valid values are 'Instance', 'IP' , 'Lambda Function' (Radio Button Selection)
            4.  Protocol    :   HTTP
            5.  Port        :   80
            6.  Protocol Ver:   HTTP1 {Send requests to targets using HTTP/1.1; supported when the request is HTTP/1.1 or 1.2}
                                Valid values are: HTTP2 and gRPC
            7.  healthchecks:
                            protocol: HTTP
                            path    : /
            8.  Advanced Health Check settings
                i.  Port                :   traffic port (Other valid value is override)
                ii. Healthy Threshold   :   3
                iii.Unhealthy Threshold :   2
                iv. Timeout             :   5
                v.  Interval            :   30
                vi. Success Codes       :   200
        g.  On the 'Register Targets'
            Whatever number of instances that you select will be added to one target group.
            For e.g.: If you have 3 instances and you selected only 2, then these 2 instances will be part for the first target group
            The 3rd instance can be added to the ALB later on, as another target group.

            This is one of the important upgraded features of ALB, and then you can route traffic to these target groups based on a 
            variety or parameters in the routing rules.
        h.  Once the targets are registered, click on create and 'ALB' will be created.
        i.  Now navigate to the 'Load Balancer' on the left vertical menu and look for your newly created ALB.
        j.  Under ALB - 'Description' look for 'DNS Name': This is the url that be used to access the ALB from anywhere.
    
    Q12: How to add a new target group to an existing ALB?
    A12: Following are the steps
        a.  Login to the EC2 Dashboard
        b.  In the left side vertical menu, under 'Load Balancing' click 'Target Groups'
        c.  'Create target group'
            Under Basic configuration:
            1.  Target Group:   New Target Group
            2.  Name        :   Provide a target group name
            3.  Target Type :   We will select 'Instance' since we will map EC2 instance to this ALB
                            :   Valid values are 'Instance', 'IP' , 'Lambda Function' (Radio Button Selection)
            4.  Protocol    :   HTTP
            5.  Port        :   80
            6.  Protocol Ver:   HTTP1 {Send requests to targets using HTTP/1.1; supported when the request is HTTP/1.1 or 1.2}
                                Valid values are: HTTP2 and gRPC
            7.  healthchecks:
                            protocol: HTTP
                            path    : /
            8.  Advanced Health Check settings
                i.  Port                :   traffic port (Other valid value is override)
                ii. Healthy Threshold   :   3
                iii.Unhealthy Threshold :   2
                iv. Timeout             :   5
                v.  Interval            :   30
                vi. Success Codes       :   200
        d.  On the 'Register Targets' page
            1.  Select the instance you want to add to this new target group
            2.  Click on 'Include as pending below'
            3.  Under 'Targets': This new entry will show as 'Pending'
        e.  Now we have a new target group created, it can now be added to the ALB.
        f.  In the left side vertical menu, under 'Load Balancing', click on 'Load Balancers'
        g.  Once the 'Load Balancer' page opens, select the ALB that you want to modify.
        h.  Click 'Listeners' and then 'Add Listeners'
        j.  Under 'Rules' click on 'view/edit' rules.
        k.  On the 'Rules' page, click on '+' on the header.
        l.  Add the 'Add Condition'd for IF and 'Add action' for THEN and click save.

    Q13: What is NLB or Network Load Balancer?
    A13: Network Load balancers operate at layer 4, and allow you to 
        a.  Forward TCP and UDP traffic to your instances.
        b.  Handle millions of requests per seconds, so extremely high performance
        c.  Very low latency ~ 100ms
        d.  Supported protocols (TCP, TLS, UDP)
    
    Special Note:
        1.  NlB has ONE STATIC IP per AZ, and supports assigning Elastic IP (Helpful for whitelisting specific IP)
        2.  NLBs are used for extreme performance, TCP or UDP traffic.
        3.  Not included in the Free-Tier
    
    Q14: How to create a Network Load Balancer?
    A14: Following are the steps
        a.  Login to the EC2 Dashboard
        b.  In the left side vertical menu, under 'Load Balancing' click on 'Load Balancers' then click on 'Create Load Balancer'
        c.  select 'Network Load Balancer' and click on create.
        d.  Under 'Basic Configuration'
            1.  Provide a name for your 'Load Balancer'
            2.  Select a valid scheme (valid values are 'Internet-Facing or Internal)
            3.  Select a valid 'IP Address Type' (valid values are IPV4, DualStack)
            4.  Network-Mapping:
                i.  Select the default VPC.
                ii. Mappings: Select the AZs you wish to attach to the NLB.
                iii.When you select the AZ, under particular AZ you will have an option of 'IPV4 Address'
                    This will have two valid values ('Assigned by AWS' and 'Use an elastic IP address')
                    ** This is a special feature only for NLB to have a dedicated static IP for whitelisting.
            5.  Under 'Listeners and Routing'
                Protocol:   TCP
                Port    :   80
                Default Action: Foward to - Select a Target Group here (if you have one existing, else create on.)
                Click on 'Add Listener.
            6.  Advanced Health Check settings
                i.  Port                :   traffic port (Other valid value is override)
                ii. Healthy Threshold   :   3
                iii.Unhealthy Threshold :   2
                iv. Timeout             :   5
                v.  Interval            :   30
                vi. Success Codes       :   200
        e.  Under 'Register Targets', select the instance and then 'Include as pending below'
        f.  The EC2 instance may show as 'Unhealthy' depending on, if correct security groups are not mapped.
        g.  Make sure, correct security groups are added to the Instances.

    Q15: What is Load Balancer Stickiness?
    A15: Load Balancer stickiness is the mechanism that ensures the same client is always redirected to the same instances behind LB
        This options works on both the CLB and ALB.
        This mechanism is implemented with the help of 'cookie' which has an expiration date that you can control.
        Enabling stickiness may bring imbalance to the load over the backend EC2 instances.

        Special Note:
            USE CASE: Make sure the user doesn't lose his/her session data.
            1.  Stickiness for CLB: Can be enabled at the CLB level
            2.  Stickiness for ALB: Can be enabled at the Target Group level.
        
        Once you enable the stickiness, you have to provide the duration for the stickiness after which stickiness will expire
        The minimum value is 1 second while the maxixum value is 7 days.
    
    Q16: What is cross-zone load balancing?
    A16: Consider the following scenario:
        You have two AZs: AZ1 and AZ2; and AZ1 has LB as LB1, while AZ2 has LB as LB2.
        Now, LB1 has two EC2 instances attached to it and LB2 has 8 instances attached to it.
        So, over all we have 10 EC2 instances with two different LBs, this is a highly imbalanced situation for traffic.

        With Cross Zone Load balancing:
        Even if the client is sending equal (50%) traffic to both the LBs, each LB will distribute even (10%) traffic each EC2 instance.

        Without Cross Zone load balacing:
        With client sending equal(50%) traffic to both the LBs, LB1, will eventually end up 25% of traffic to each EC2 in AZ1, while LB2 
        will send 6.25% traffic to each instance in AZ2

        Special Note:  Cross Zone Load Balacing is Enabled on Disabled by default, depending on the type of the LB.
        a.  CLB:
            1.  If the CLB is created from the management console, 'Cross Zone Load Balancing' is enabled by default.
            2.  If the CLB is creted by 'CLI/API', 'Cross Zone Load Balancing' is disabled by default.
            3.  No Additional Charges are incurred between inter AZ data {when Cross Zone Load Balancing is enabled}
        
        b.  ALB:
            1.  'Cross Zone Load Balacing' is always one and cannot be disabled.
            2.  No Additional Charges are incurred between inter AZ data
        
        c.  NLB:
            1.  'Cross Zone Load Balancing' is DISABLED be default, but can be 'Enabled'
            2.  Additional charges are incurred for inter AZ data {when Cross Zone Load Balancing is enabled}

    Q17: Explain SSL/TLS?
    A17: An SSL certificate allows the traffic betweeb your clients and your load balancer to be encrypted in transit (in-flight encryption)
        a.  SSL refers to the 'Secure Socket Layer', used to encrypt connections.
        b.  TLS refers to Transport Layer security, which is a newer version.
        
        Now a days, TLS certificates are mainly used
        Public certificates are issued by Certificate Authorities (CA): Symantec, GoDaddy, Digicert etc.

        Special Note: SSL certificates have an expiration date and must be renewed. 

        Load Balancer SSL certificates

                    (HTTPS encrypted over www)          (HTTP over private VPC)
        USERS   ----------------------------->  ELB ----------------------------->  EC2
                <-----------------------------      <-----------------------------
        
        a.  Load Balancer uses an X.509 certificate (SSL/TLS Server Certificate)
        b.  You can manage certificates using ACM (AWS Certificate Manager)
        c.  You can create / upload your own certificates as well.
        d.  You must configure HTTPS listener for your ELB
            1.  You must specificy a default certificate.
            2.  You can add an optional list of certs to support multiple domains
            3.  Clients can use SNI (Server Name Indication) to specify the hostname they want to reach
            4.  Ability to specify a security policy to support older versions of SSL/TLS (legacy clients)


    Q18. What is SNI (Server Name Indication)?
    A18: SNI (Server Name Indication) solves the problem of loading multiple SSL certificates onto one web server (to server multiple websites)
        Its a newer protocol and requires the client to indicate the hostname of the target server in the initial SSL handshake
        The server will then find the correct certificate, or return the default one.

        Special Note: SNI only works with ALB, NLB and CloudFront.
        Does NOT work with CLB.

        ELB with SSL Certificates:
        a.  CLB:
            1.  Supports only one SSL certificate
            2.  Must use multiple CLBs for multiple hostname with multiple SSL certificates.
        b.  ALB:
            1.  Supports multiple listeners with multiple SSL certificates.
            2.  Uses server name indication (SNI) to make it work
        c.  NLB:
            1.  Supports multiple listeners with multiple SSL certificates.
            2.  Uses server name indication (SNI) to make it work

    Q19: What is Connection Draining in CLB or Deregistration Delay in ALB/NLB?
    A19: 'Connection Draining in CLB' or 'Deregistration Delay in ALB/NLB' refers to the 'Time to complete "In-flight requests", 
        while the instance is de-registering or unhealthy.

        While this phenomena happens:
        a.  ELB will stop sending new requests to the instances that is 'de-registering'
        b.  The default configuration to handling existing requests while the instance is 'de-registering' is 300 seconds, but can be between 1s to 1HR
        c.  This configuration can be disbaled as well.
        d.  This number should be configured based on your application behaviour.

-----------------------------------------------------------------------------------------------------------------------------------------------------------
ASG: Auto Scaling Group
-----------------------------------------------------------------------------------------------------------------------------------------------------------

Auto Scaling Group:
    The load on your websites and applications change hence we need to either scale up or scale down depending on the transaction volume.
    Cloud platforms provide the feasibility to add / remove servers with a click of few buttons.

    The goal of Auto Scaling Group (ASG) is to:
    a.  Scale OUT (Add EC2 Instances) to match an increased load
    b.  Scale IN (Remove EC2 Instances) to match a decreased load
    c.  Ensure we have a minimum and maximum number of machines running
    d.  Automatically register new instances to a load balancer. (Via Automation)

    1.  Launch Configuration / Launch Templates for ASG have the following attributes:
        a.  AMI + Instance Type
        b.  EC2 User Data
        c.  EBS Volumes
        d.  Security Groups
        e.  SSH Key pairs
    2.  Minimum Size / Maximum Size / Initial capacity
    3.  Network + Subnets Information
    4.  Load Balancer Information
    5.  Scaling Policies

    Special Notes:
        a.  IAM roles attached to the ASG will automatically get assigned to the EC2 instances.
        b.  ASG is free to use, however the cost is incurred for the underlying resources being launched.
        c.  ASG does not stop or start instances, it will terminate the instance when LB marks the instance as unhealthy and REPLACES them
        d.  Having instances under ASG< mean that if they get terminated for whatever reason, ASG will automatically create new ones as replacement.

    Q01: What is an Auto Scaling Alarms?
    A01: It is possible to scale an ASG based on CloudWatch alarms.
        A Cloudwatch alarm monitors a metric (such as an Average CPU)
        Metrics are computed for the overall ASG instances.
        Based on the alarms:
            a.  We can create scale-out policies (increase the number of instances)
            b.  We can create scale-in policies (decrease the number of instances)

                                                                            Auto Scaling Group
                                                                ---------------------------------------------
        CloudWatch --------Trigger Scaling------------------->  | EC2-1; EC2-2; EC2-3......EC2-N            |
        ALARM                                                   ---------------------------------------------
    
    Q02: What are Auto Scaling Rules?
    A02: Its now possible to define 'Better' auto scaling rules that are directly managed by EC2, based on
        a.  Target Average CPU Usage
        b.  Number of requests on the ELB per instance. (for e.g. 100 requests to one instance from ELB to trigger scaling)
        c.  Average Network In
        d.  Average Network Out
    
        Auto Scaling Custom Metrics:
        We can auto scale based on a custom metric as well (for e.g. number of connected users or based on a schedule)
        a.  Send Custom Metric from application on EC2 to CloudWatch (using PutMetric API)
        b.  Create CloudWatch alarm to react to low / high values
        c.  Use the CloudWatch alarm as the scaling policy for the ASG.

    Q03: How to create an Auto Scaling Group?
    A03: Following are the steps:
        a.  Login to the EC2 Dashboard
        b.  In the left side vertical menu, under 'Auto Scaling' click on 'Auto Scaling Groups' then click on 'Create Auto Scaling Group'
        c.  Provide a name for the 'Auto Scaling Group'
        d.  Under 'Launch Template' click on 'Create a Launch Template'
            1.  Provide a name for the launch template.
            2.  Provide a name for the template version description.
            3.  Under Launch Template Contents
                i.  Select an AMI
                ii. Select an Instance type
                iii.Select a Key-Pair OR you can create one
                iv. Under Network Settings - Select Virtual Private Cloud (VPC)
                v.  Select 'Security Groups': This must be accurate or else the EC2 instances will not be accessible by you or the ELB.
                vi. Select Storage
                vii.Under Advanced details, add user data that you want to use.
        e.  Now you will be redirected to 'Launch Template' and you can select the template that you created from the drop down.
        f.  Under the 'Instance Purchase options' their are two values, select the one with which you are comfortable based on cost.
            1.  Adhere to Launch Template: The Launch Template determines the purchase option (on-demand or spot) and instance type
            2.  Combine Purchase options and Instance types: Specify how much on-demand and spot capacity to launch and multiple instance types 
                (optional). This choise is most helpful for optimizing the scale and cost for a fleet of instances.
        g.  Under 'Network'
            1.  Select the default VPC
            2.  And for subnets, select the AZs you want the EC2 instances to be launched (you can select one or many)
        h.  Under 'Configure Advanced Options'
            1.  Load Balancing (Optional) : You can either use an ELB or not
                i.  No Load Balancer: Traffic to your auto scaling group will not be fronted by a load balancer.
                ii. Attach to an existing load balancer: Choose from your existing load balancers.
                iii.Attach to a new load balancer: Quickly create a basic load balancer to attach to your ASG.

            If you select an ALB (that was created before), you will need to select a Target group as well.

        i.  Under Health Checks (optional): Has two options:
            1.  EC2     :   Selected by Default and cannot be un-selected
            2.  ELB     :   Not Selected by default
            If you select the ALB in previous step, ELB must be selected in health checks.
            The idea is, if the EC2 instance is for some reason misbehaving and is deemed unhealth by LB, then it will deemed unhealthy in ASG as well.
            Thereby triggering ASG to terminate the unhealthy instance and replacing it with a new one.

        j.  Under 'Configure Group Size and Scaling policies'
            1. Select the : Desited Capacity, Minimum Capacity and Maximum capacity for count of EC2 instances to be launched.
            2. Scaling Polies are optional: This helps to dynamically resize your ASG to meet the changes in demand.
                Two Valid Values: 
                i.  None
                ii. 'Target Tracking Scaling Policy': Choose a desired outcome and leave it to the scaling policy to add and remove 
                    capacity as needed to achieve the outcome.
        k.  Instance scale-in-Protection (optional)
            If protect from scale in is enabled, newly launched instanes will be protected from scale in by default.
        l.  Review and create your 'Auto Scaling Group'.
        m.  Once the 'ASG's is created, click on its name and go to 'Activity Tab' and then to 'Activity History'
            You'll see the creation and termination of EC2 instances under 'Activity History'

    Special Note:
        If you select the ELB along with Auto Scaling Group, the EC2 instances will be automatically registered with the ELB.
        If for some reason, the EC2 instance is unhealthy, ASG will terminate it and replace it with a new one, and the new EC2 instance
        will again be automatically registered with ELB.

    Q04: How many ASG - Scaling Polcies are there?
    A04: There are 3 ASG - Scaling Policies.
        a.  Target Tracking Scaling:
            e.g.:   You want the average ASG CPU to be around 40%, then ASG will scale out or scale in to match this rule depending on the CPU.
        b.  Simple / Step Scaling:
            e.g.:   When a CloudWatch alarm is triggered (if CPU > 70%), then add 2 EC2 units
                    When a CloudWatch alarm is triggered (if CPU < 30%), then remove 1 EC2 units
            This has some more control, since YOU are deciding the number of EC2 instances instead of letting ASG Decide.
        c.  Sceduled Actions:
            This policy is based on anticipation of the usage pattern.
            e.g.:   Increase the minimum capacity to 10 EC2 instances on Black Friday at 6 AM.
    
    Q05: What is ASG - Scaling Cooldowns?
    A05: The cooldown period helps to ensure that your Auto Scaling Group doesn't launch or terminate additional instances, before the 
        previous scaling activity takes effect.

        In Addition to the default cooldown for ASG: We can create cooldowns that apply to a specific 'SIMPLE SCALING POLICY'

        USECASE:
            One common use for scaling-specific cooldowns is with a scale-in policy:
                A policy that terminates instances based on a specific criteria or metric. Because the policy terminates instances, 
                ASG needs less time to determine, whether to terminate additional instances.
            
            If the default cool down period of 300 seconds is too long:
                You can reduce costs by applying a scaling-specific cooldown period of 180 seconds to scale-in policy.
            
            If your application is scaling up and down multiple times in an hour, modify the ASG cool-down timers and the CloudWatch alarm 
            period that triggers the scale in.

-----------------------------------------------------------------------------------------------------------------------------------------------------------
Amazon RDS (Relational Database Service)
-----------------------------------------------------------------------------------------------------------------------------------------------------------
RDS stands for Relational Database Service.
Its a managed DB service for DB use SQL as a query Language.
It allows you to create databases in the cloud that are managed by AWS:
    a.  Postgres
    b.  MySQL
    c.  MariaDB
    d.  Oracle
    e.  Microsoft SQL Server
    f.  Aurora (AWS Proprietry Database)

Advantage over using RDS versus deploying DB on EC2
RDS is a managed service
    a.  Automated Provisioning, OS patching
    b.  Continuous backup and restore to specific timestamp (Point in time restore)
    c.  Monitoring Dashboards
    d.  Read Replicas for improved read performance
    e.  Multi AZ setup for DR (Disasater Recovery)
    f.  Maintenance windows for upgrades
    g.  Scaling Capability (vertical and horizontal)
    h.  Storage backed by Elastic Block Store (gp2 or io1)

But, you cannot SSH into your RDS instances, since its a Managed Service.

RDS Backups:
    a.  Backups are automatically enabled in RDS.
    b.  Automated Backups:
        1.  Daily Full backup of the database (during the maintenance window)
        2.  Transaction Logs are backed-up by RDS every 5 minutes
        3.  => ability to restore at any point in time (from oldest backup to 5 mins ago)
        4.  7 Day retension (can be increased to 35 days)
    c.  DB Snapshots.
        1.  DB snapshots are manually triggered by the user
        2.  Retention of backup for as long as you want

RDS: Storage Auto Scaling
    a.  Helps you increase storage on your RDS DB instance dynamically
    b.  When RDS detects you are running out of free database storage, it scales automatically
    c.  This helps you avoid manually scaling your database storage
    d.  You have to set "Maximum Storage Threshold" [maximum limit of DB storage]
    e.  It helps you automatically modify storage if:
        1.  Free storage is less than 10% of allocated storage
        2.  Low-Storage lasts at least 5 minutes (depending on transaction writes)
        3.  6 hours have passed since last modification
    f.  Useful for applications with un-predicable workloads
    g.  Supports all RDS Database Engines [Postgres, MySQL, MariaDB, Oracle, Microsoft SQL Server]

    Q01: What is RDS Read Replication?
    A01: Replication means a continuous copy of the data from one Database (master/publisher) to another Database (slave/subscriber). The slave/subscriber
         Databases can be on the same server or different servers and contain the replica of the master database. The main aim of replication is to 
         provide fault-tolerant access to data in case of failure of the master. Also, load balancing and routing some of the queries to the subscriber 
         database to reduce the load on the primary Database.
         Amazon RDS Read Replication is a feature on Amazon RDS that allows you to create one or more read copies (up to 5) of the primary Database within 
         the same or different AWS region. The data from the master database is asynchronously copied to these slave or secondary databases.

        a.  Up to 5 Read Replicas
        b.  Read Replicas can be created - Within AZ, or Across AZs or Across Regions.
        c.  Replication is ASYNC, so reads are eventually consistent
        d.  Replicas CAN be promoted to their own Database, and then they will follow their own lifecycle.
        e.  Applications must update the connection string to leveragee read replicas.

        USECASE:
            Suppose you have a production database, that is operating under normal load. Now for some analytics or reporting tasks, you need access the 
            production database.
            a.  If both the application and the reporting tasks are accessing the production database simultaneously, then it may increase the load on the 
                database.
            b.  To avoid this, as a solution architect, you can create a "READ REPLICA" , so that only the application is working on the production DB, 
                while the reporting tasks are working through the 'READ REPLICA'
            c.  This way the production database is not overloaded and the application remains un-affected.
        Special Note:
            Read replicas are used for 'SELECT' only statements (not Insert, Update or Delete)
    
    Q02: Explain associated costs for RDS Read Replicas - Across the network?
    A02: Usually for AWS managed services, their is no network cost when the data travels from One AZ to another, however their are exceptsion.
        a.  For RDS Read Replicas: If your RDS DB and RDS Read Replica are in the same region (may or may not be in different AZ), then no
            replication charges will be incurred.
        b.  For RDS Read Replicas: If you RDS DB and RDS Read Replica are in different regions, then replication charges will be incurred.
    
    Q03: What is RDS Multi AZ?
    A03: RDS multi AZ is used for disastor Recovery
        a.  Unlike READ REPLICAS (which are A-SYNC replication), Multi AZ is SYNC Replication.
        b.  RDS Multi AZ is one DNS name : And supports automatic Failover from the Master DB to the Standby DB
        c.  RDS Multi AZ increases the application availability, due to automatic Failover
        d.  Failover Will trigger:
            1.  Due to Loss of AZ
            2.  Due to Loss of network
            3.  Due to Instance failure
            4.  Due to storage failure
        e.  Their are no manual intervention needed in applications to move the connection from Master DB to Standby DB, since the failover 
            happens, beneath the DNS layer.
        f.  The STANDBY DB cannot be used for SCALING, no body can directly read from or write to 'STANDBY' DB unless it becomes Master.

        Special Note:
        Common Exam Question: Can Read Replicas be setup as 'Multi-AZ' for Disaster Recovery (DR) purposes?
        Answer              : YES
    
    Q04: How to convert a RDS-Single AZ to RDS-Multi AZ?
    A04: To conver a RDS-Single AZ to RDS-Multi AZ, we just need to modify the database and convert it.
        a.  Their is no downtime to convert RDS from single-AZ to multi-AZ, since we dont need to stop the DB.
        b.  When you convert a single-AZ to multi-AZ:
            1.  A snapshot is taken from the Master DB
            2.  A new standby DB is created.
            3.  The snapshot is written to the standby DB
            4.  After the snapshot is written, SYNC replication happens between master and standby, until Standy catches up completely.

    Q05: What is Data at rest?
    A05: Data at rest refers to data residing in computer storage in any digital form. This data type is currently inactive and is not 
        moving between devices or two network points. No app, service, tool, third-party, or employee is actively using this type of info.
        At rest is not a permanent data state. As soon as someone requests a file, that data moves across a network and becomes 
        in-transit data. Once someone (or something) starts processing a file, the data enters the in-use state

        Data at rest includes both structured and unstructured data. Some examples of where a company can store data at rest are:

        a.  Hard and SSD drives on PCs and laptops.
        b.  Database servers.
        c.  The cloud.
        d.  At a third-party colocation facility.
        e.  Edge-point devices and portable storage (mobile phones, USBs, tablets, portable hard drives, etc.).
        f.  Network-attached storage (NAS).

        Static data storage typically has a logical structure and meaningful file names, unlike individual in-motion packets moving through 
        a network. Data at rest also typically contains the company's most valuable and private info, such as:

        a.  Financial documents (past transactions, bank accounts, credit card numbers, etc.).
        b.  Intellectual property (product information, business plans, schematics, code, etc.).
        c.  Contacts.
        d.  Marketing data (user interactions, strategies, directions, leads, etc.).
        e.  Employee and customer personal info.
        f.  Healthcare data.
        g.  Contracts.
        h.  Supply chain info.

